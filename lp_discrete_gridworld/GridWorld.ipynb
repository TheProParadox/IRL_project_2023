{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directions\n",
    "#0 is left\n",
    "#1 is down\n",
    "#2 is right\n",
    "#3 is Up\n",
    "\n",
    "# 1.1 displays your position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class myGridWorld:\n",
    "    \n",
    "    size=5\n",
    "    RewardGrid=np.zeros([5,5])\n",
    "    RewardGrid[0][4]=1\n",
    "    PositionGrid=np.zeros([5,5])\n",
    "    PositionGrid[4][0]=1.1\n",
    "    action_space=4\n",
    "    noisyMoveChance=0.3\n",
    "    currI=4\n",
    "    currJ=0\n",
    "    DoneStatus=False\n",
    "    EnableNoise=True\n",
    "    observation_spaces=size*size\n",
    "    \n",
    "    def __init__(self,size=5,noisyMoveChance=0.3,EnableNoise=True):\n",
    "        self.basicReset()\n",
    "        self.EnableNoise=EnableNoise\n",
    "        if(0<size):\n",
    "            self.size=int(size)\n",
    "            self.RewardGrid=np.zeros([size,size])\n",
    "            self.RewardGrid[0][size-1]=1\n",
    "            self.PositionGrid=np.zeros([size,size])\n",
    "            self.PositionGrid[size-1][0]=1.1\n",
    "            self.observation_spaces=self.size*self.size\n",
    "            self.currI=size-1\n",
    "            self.currJ=0\n",
    "            self.observation_spaces=self.size*self.size\n",
    "        if(0<noisyMoveChance and noisyMoveChance<1):\n",
    "            self.noisyMoveChance=noisyMoveChance\n",
    "            \n",
    "    def basicReset(self):\n",
    "        self.size=5\n",
    "        self.RewardGrid=np.zeros([5,5])\n",
    "        self.RewardGrid[0][4]=1\n",
    "        self.PositionGrid=np.zeros([5,5])\n",
    "        self.PositionGrid[4][0]=1.1\n",
    "        self.action_space=4\n",
    "        self.noisyMoveChance=0.3\n",
    "        self.currI=4\n",
    "        self.currJ=0\n",
    "        self.DoneStatus=False\n",
    "        self.EnableNoise=True\n",
    "        self.observation_spaces=self.size*self.size\n",
    "            \n",
    "    def reset(self,size=5,noisyMoveChance=0.3,EnableNoise=True):\n",
    "        self.__init__(size,noisyMoveChance,EnableNoise)\n",
    "        return self.currI*self.size+self.currJ\n",
    "    \n",
    "    def printRewardGrid(self):\n",
    "        for i in range(len(self.RewardGrid)):\n",
    "            for j in range(len(self.RewardGrid[0])):\n",
    "                print(self.RewardGrid[i][j],end=' ')\n",
    "            print()\n",
    "            \n",
    "    def printPositionGrid(self):\n",
    "        for i in range(len(self.PositionGrid)):\n",
    "            for j in range(len(self.PositionGrid[0])):\n",
    "                print(self.PositionGrid[i][j],end=' ')\n",
    "            print()\n",
    "            \n",
    "    def getPositionGrid(self):\n",
    "        return self.PositionGrid\n",
    "            \n",
    "    def render(self):\n",
    "        self.printPositionGrid()\n",
    "        \n",
    "    def getAvailableMoves(self):\n",
    "        return self.action_space\n",
    "    \n",
    "    def getSize(self):\n",
    "        return self.size\n",
    "            \n",
    "    def move(self,action):\n",
    "        randNum=random.random()\n",
    "        if(self.EnableNoise and randNum<=self.noisyMoveChance):\n",
    "            self.makeNoisyMove(action)\n",
    "        else:\n",
    "            self.makeProperMove(action)\n",
    "        return self.currI,self.currJ,self.currI*self.size+self.currJ,self.RewardGrid[self.currI][self.currJ],self.DoneStatus\n",
    "        \n",
    "    def makeNoisyMove(self,action):\n",
    "        randNum=random.randint(0,3)\n",
    "        self.makeProperMove(randNum)\n",
    "        \n",
    "    def makeProperMove(self,action):\n",
    "        if(action==0):#Left\n",
    "            if(0<self.currJ):\n",
    "                self.PositionGrid[self.currI][self.currJ]=0\n",
    "                self.currJ-=1\n",
    "                self.PositionGrid[self.currI][self.currJ]=1.1\n",
    "        elif(action==1):#1 is down\n",
    "            if(self.currI<self.size-1):\n",
    "                self.PositionGrid[self.currI][self.currJ]=0\n",
    "                self.currI+=1\n",
    "                self.PositionGrid[self.currI][self.currJ]=1.1\n",
    "        elif(action==2):#2 is right\n",
    "            if(self.currJ<self.size-1):\n",
    "                self.PositionGrid[self.currI][self.currJ]=0\n",
    "                self.currJ+=1\n",
    "                self.PositionGrid[self.currI][self.currJ]=1.1\n",
    "        elif(action==3):#3 is Up\n",
    "            if(0<self.currI):\n",
    "                self.PositionGrid[self.currI][self.currJ]=0\n",
    "                self.currI-=1\n",
    "                self.PositionGrid[self.currI][self.currJ]=1.1\n",
    "                \n",
    "        if(self.currI==0 and self.currJ==self.size-1):\n",
    "            self.DoneStatus=True\n",
    "            \n",
    "    def step(self,action):\n",
    "        return self.move(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGridWorldTrainer:\n",
    "    \n",
    "    env=[]\n",
    "    Q=[]\n",
    "    matrix=[]\n",
    "    Trajectories=[]\n",
    "    DirectionalMatrix=[]\n",
    "    \n",
    "    def trainModel(self,model):\n",
    "        env=self.env\n",
    "        alpha = 0.6\n",
    "        gamma = 0.9\n",
    "        Q = np.zeros([env.observation_spaces, env.action_space])\n",
    "        for episode in range(1,10001):\n",
    "            done = False\n",
    "            TotalReward = 0\n",
    "            state = env.reset()\n",
    "            while done != True:\n",
    "                    if(episode<500):\n",
    "                        action = random.randint(0,3)\n",
    "                    else:\n",
    "                        action=np.argmax(Q[state])\n",
    "                    i,j,state2, reward, done = env.step(action)\n",
    "                    Q[state,action] += alpha * (reward + gamma* np.max(Q[state2]) - Q[state,action])\n",
    "                    TotalReward += reward\n",
    "                    state = state2\n",
    "        self.Q=Q\n",
    "        return Q\n",
    "    \n",
    "    def getDirections(self,Q):\n",
    "        matrix=[]\n",
    "        for i in range(0,25):\n",
    "            matrix.append(np.argmax(Q[i]))\n",
    "        matrix=np.reshape(matrix,(5,5))\n",
    "        DirectionalMatrix=[]\n",
    "        for i in range(5):\n",
    "            row=[]\n",
    "            for j in range(5):\n",
    "                if(matrix[i][j]==0):\n",
    "                    row.append('\\u2190')\n",
    "                elif(matrix[i][j]==1):\n",
    "                    row.append('\\u2193')\n",
    "                elif(matrix[i][j]==2):\n",
    "                    row.append('\\u2192')\n",
    "                elif(matrix[i][j]==3):\n",
    "                    row.append('\\u2191')\n",
    "            DirectionalMatrix.append(row)\n",
    "#         for row in DirectionalMatrix:\n",
    "#             print(row)\n",
    "        self.DirectionalMatrix=DirectionalMatrix\n",
    "        self.matrix=matrix\n",
    "        return matrix\n",
    "            \n",
    "    def getTrajectories(self,matrix,numTrajectories):\n",
    "        Trajectories=[]\n",
    "\n",
    "        for iters in range(numTrajectories):\n",
    "            path=[]\n",
    "            done=False\n",
    "            state = self.env.reset()\n",
    "            TotalReward = 0\n",
    "            path.append(state)\n",
    "            i=int(state/self.env.size)\n",
    "            j=state%self.env.size\n",
    "            while done != True:\n",
    "                action=matrix[i][j]\n",
    "                i,j,state2, reward, done = self.env.step(action)\n",
    "                TotalReward += reward\n",
    "                state = state2\n",
    "                path.append(state)\n",
    "\n",
    "            Trajectories.append(path)\n",
    "#         for i in Trajectories:\n",
    "#             print(i)\n",
    "        self.Trajectories=Trajectories\n",
    "        return Trajectories\n",
    "\n",
    "    def allInOne(self,model,numTrajectories):\n",
    "        self.env=model\n",
    "        Q=self.trainModel(model)\n",
    "        matrix=self.getDirections(Q)\n",
    "        return self.getTrajectories(matrix,numTrajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 0]\n",
      "[3 3 2 2 3]\n",
      "[3 3 3 2 3]\n",
      "[3 2 3 3 3]\n",
      "[3 2 3 3 3]\n",
      "['→', '→', '→', '→', '←']\n",
      "['↑', '↑', '→', '→', '↑']\n",
      "['↑', '↑', '↑', '→', '↑']\n",
      "['↑', '→', '↑', '↑', '↑']\n",
      "['↑', '→', '↑', '↑', '↑']\n",
      "[0.35487585 0.35878461 0.58946554 0.34985628]\n",
      "[0.41155589 0.42279086 0.73178905 0.43660594]\n",
      "[0.48751984 0.49461514 0.88017446 0.48042283]\n",
      "[0.5448184  0.56351603 0.99836669 0.5295759 ]\n",
      "[0. 0. 0. 0.]\n",
      "[0.32816079 0.32051778 0.33658891 0.51925273]\n",
      "[0.37140773 0.38225555 0.3619561  0.52277334]\n",
      "[0.45119543 0.42923475 0.76619007 0.45517711]\n",
      "[0.53613132 0.51369334 0.86553182 0.53276744]\n",
      "[0.5675795  0.5806573  0.58172353 0.99999762]\n",
      "[0.31534766 0.30152343 0.31947603 0.48011292]\n",
      "[0.35787268 0.35849722 0.35000357 0.47165947]\n",
      "[0.38444608 0.35963973 0.38631405 0.53011134]\n",
      "[0.44194994 0.46266727 0.65654364 0.43638598]\n",
      "[0.43432125 0.40491967 0.48433895 0.84020758]\n",
      "[0.26147133 0.25907671 0.26626061 0.42292652]\n",
      "[0.29175303 0.2903513  0.46304804 0.28593924]\n",
      "[0.35509125 0.35634437 0.35146273 0.61348826]\n",
      "[0.35911612 0.36048535 0.3620877  0.58903814]\n",
      "[0.35478345 0.36123321 0.35904149 0.68820405]\n",
      "[0.25596736 0.25328475 0.25537248 0.36962379]\n",
      "[0.27361632 0.27729524 0.40678412 0.27563654]\n",
      "[0.31410323 0.31251376 0.31261546 0.51833801]\n",
      "[0.32196344 0.31625111 0.31256977 0.4901064 ]\n",
      "[0.3190012  0.31057231 0.30923871 0.52085417]\n"
     ]
    }
   ],
   "source": [
    "sampleGrid=myGridWorld()\n",
    "sampleGridTrainer=myGridWorldTrainer()\n",
    "sampleTrajectories=sampleGridTrainer.allInOne(sampleGrid,20)\n",
    "# for i in sampleTrajectories:\n",
    "#     print(i)\n",
    "    \n",
    "for i in sampleGridTrainer.matrix:\n",
    "    print(i)\n",
    "    \n",
    "for i in sampleGridTrainer.DirectionalMatrix:\n",
    "    print(i)\n",
    "    \n",
    "for i in sampleGridTrainer.Q:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================================================================================\n",
    "\n",
    "#Testing data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in sampleGridTrainer.DirectionalMatrix:\n",
    "#     print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in DirectionalMatrix:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# mydata = [Q,matrix,DirectionalMatrix]\n",
    "# outputFile = 'model.data'\n",
    "# fw = open(outputFile, 'wb')\n",
    "# pickle.dump(mydata, fw)\n",
    "# fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# inputFile = 'model.data'\n",
    "# fd = open(inputFile, 'rb')\n",
    "# dataset = pickle.load(fd)\n",
    "# print (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\u2190 ←\n",
    "# \\u2191 ↑\n",
    "# \\u2192 →\n",
    "# \\u2193 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 is left\n",
    "#1 is down\n",
    "#2 is right\n",
    "#3 is Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in Trajectories:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
